{
  "disqus_url": "http://blog.simiacryptus.com/blog/modeling_network_latency/",
  "disqus_title": "Modeling Network Latency",
  "Title": "Modeling Network Latency",
  "Pubdate": "2015-10-25",
  "Keywords": [],
  "Tags": [],
  "Slug": "modeling_network_latency",
  "Section": "post",
  "comments": true
}
<span style="font-family: inherit;">Website request latencies, as a dataset, are odd. I can think of no other dataset I have encountered so frequently in my work, but when you do research about this dataset online, you find amazingly little compared to similar topics. Therefore, let's talk about this today - specifically, what does the ideal statistical model for website latency look like?</span><br /><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;">The background for statistical modeling is large, and it is covered in several different approaches. I prefer intuitive arguments and an information-theoretic approach, so for background I refer readers to these articles:</span><br /><ol><li><a href="https://en.wikipedia.org/wiki/Information_theory"><span style="font-family: inherit;">https://en.wikipedia.org/wiki/Information_theory</span></a></li><li><a href="https://en.wikipedia.org/wiki/Cross_entropy"><span style="font-family: inherit;">https://en.wikipedia.org/wiki/Cross_entropy</span></a></li><li><a href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy"><span style="font-family: inherit;">https://en.wikipedia.org/wiki/Principle_of_maximum_entropy</span></a></li><li><a href="https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution"><span style="font-family: inherit;">https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution</span></a></li></ol><span style="font-family: inherit;">For an illustrative example of a probability modeling for timing events, let's talk about the Erlang distribution for a moment.</span><br /><h4><b><span style="font-family: inherit;">The Erlang Distribution</span></b></h4><a href="http://4.bp.blogspot.com/-w8cBgiuy9Hg/Vi1WNE_b7sI/AAAAAAAAAJY/oFo9LRM_0jw/s1600/network%2Blatency%2Bmodeling_11.gif" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><span style="font-family: inherit;"><img border="0" height="137" src="http://4.bp.blogspot.com/-w8cBgiuy9Hg/Vi1WNE_b7sI/AAAAAAAAAJY/oFo9LRM_0jw/s320/network%2Blatency%2Bmodeling_11.gif" width="320" /></span></a><span style="font-family: inherit;">If we study the statistics of a timed event, we can first point out that the maximum entropy distribution of a positive variable with a given expectation value is the exponential distribution. If all we know is that the process latency can't be negative, and we measure its mean value, this distribution is a natural choice.</span><br /><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;">However, if we look at many datasets, the latency is not only strictly positive, but it also trends quickly to zero near zero. That is, many processes cannot complete instantaneously and are unlikely to complete as fast as theoretically possible. One way to express this expectation could be that P[0]=0, P'[0]=0, P''[0]=0 etc.</span><br /><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;">What if, just for fun, we modeled the time it would take for 2, 3, or more successive identical exponentially-modeled processes? That gives us a model with only one additional integer ("k") parameter on top of the exponential's single continuous parameter. The distribution is obtained via convolution operations, which produce what is known as the Erlang distribution.&nbsp;</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">If we plot the first few values of k, we notice the behavior we sought above; each successive convolution has an additional 0 at a higher order&nbsp;</span></span><span style="line-height: 17.0001px;">derivative</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;at x=0. It is obvious why k is called the "shape" parameter.</span></span><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-q6vmbLPxR1A/Vi1d__VaoQI/AAAAAAAAAKE/WK13iabAgko/s1600/network%2Blatency%2Bmodeling_12.gif" imageanchor="1"><span style="font-family: inherit;"><img border="0" src="http://4.bp.blogspot.com/-q6vmbLPxR1A/Vi1d__VaoQI/AAAAAAAAAKE/WK13iabAgko/s1600/network%2Blatency%2Bmodeling_12.gif" /></span></a></div><b style="line-height: 17.0001px;"><span style="font-family: inherit;">Our Dataset</span></b><br /><span style="font-family: inherit;"><b style="line-height: 17.0001px;"><br /></b> </span><a href="http://3.bp.blogspot.com/-3ZpMg925Kcc/Vi1bTwugOCI/AAAAAAAAAJs/tS8JYPPo6CU/s1600/network%2Blatency%2Bmodeling_60.gif" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><span style="font-family: inherit;"><img border="0" height="121" src="http://3.bp.blogspot.com/-3ZpMg925Kcc/Vi1bTwugOCI/AAAAAAAAAJs/tS8JYPPo6CU/s200/network%2Blatency%2Bmodeling_60.gif" width="200" /></span></a><span style="font-family: inherit;"><span style="line-height: 17.0001px;">In order to give our comparison a solid basis in reality, we use a publicly&nbsp;</span></span><span style="line-height: 17.0001px;">available</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;dataset. I was&nbsp;</span></span><span style="line-height: 17.0001px;">surprised</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;that I couldn't find any publicly&nbsp;</span></span><span style="line-height: 17.0001px;">available</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;access-log type datasets that include latency. I did,&nbsp;however, find the <a href="https://pdos.csail.mit.edu/archive/p2psim/kingdata/">"King" dataset</a> collected by and published by MIT. King is a tool to map out network latency based on multi-hop pings, so the dataset is essentially a radar map of the topology of the internet. We only use a very small slice of a small chunk of this dataset - 100k records of ping times across a single network link.</span></span><br /><span style="font-family: inherit;"><br /></span><a href="http://3.bp.blogspot.com/-CWzTANdIT1g/Vi1cWoLkljI/AAAAAAAAAJ4/ZJOHLaMgBgQ/s1600/network%2Blatency%2Bmodeling_61.gif" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><span style="font-family: inherit;"><img border="0" height="122" src="http://3.bp.blogspot.com/-CWzTANdIT1g/Vi1cWoLkljI/AAAAAAAAAJ4/ZJOHLaMgBgQ/s200/network%2Blatency%2Bmodeling_61.gif" width="200" /></span></a><span style="font-family: inherit;"><span style="line-height: 17.0001px;">This dataset has several&nbsp;</span></span><span style="line-height: 17.0001px;">noticeable</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;characteristics. First, it has a minimum time&nbsp;that is measurably positive - website requests never complete instantly or, of course, faster! Second, it has a really long tail. Both of these facts suggest we should look at the data in the Log[x] domain, which shows a few additional features. First, it appears to have a pair of Gaussian peaks, and a third broad-spectrum Gaussian curve. These curve shapes in the Log[x] domain suggest a Log-Normal model. However, the graphs suggest additional artifacts such as spikes and even-longer-tail behavior.</span></span><br /><h4><b><span style="font-family: inherit;">Models Considered</span></b></h4><span style="font-family: inherit;">For this analysis we discuss several different models. Models consist of the following distribution families:</span><br /><ol><li><span style="font-family: inherit;"><a href="https://en.wikipedia.org/wiki/Hypoexponential_distribution">Hypoexponential</a>&nbsp;Distribution (e.g. <a href="https://en.wikipedia.org/wiki/Erlang_distribution" target="_blank">Erlang</a> Distribution) - Models successive exponential processes. The general case allows events to have varying expectations, Erlang models assume them to be identical.</span></li><li><span style="font-family: inherit;"><a href="https://en.wikipedia.org/wiki/Gamma_distribution" target="_blank">Gamma</a> Distribution - An alternate generalization of the Erlang distribution, where the "number" of identical successive events modeled may be non-integer. (e.g. shape parameter of k=1.3)</span></li><li><span style="font-family: inherit;"><a href="https://en.wikipedia.org/wiki/Log-normal_distribution" target="_blank">LogNormal</a> Distribution - A <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank">Gaussian</a> distribution remapped via e^x</span></li><li><span style="font-family: inherit;"><a href="https://en.wikipedia.org/wiki/Pareto_distribution" target="_blank">Pareto</a> Distribution - This distribution is useful in modeling a number of phenomena exhibiting power-law long-tail behaviors. It is essentially a Log[x] remapping of an exponential distribution.</span></li><li><span style="font-family: inherit;"><a href="https://en.wikipedia.org/wiki/Mixture_model" target="_blank">Mixture</a> Models - Sub-models can be combined in a linear combination to produce a mixed model. Note there are many logical ways to combine two models, this being only one. Another would be convolution as we discussed with the Erlang distribution. Mixture models are mathematically convenient as they allow the Expectation-Maximization algorithm to be used.</span></li></ol><span style="font-family: inherit;"><span style="line-height: 17.0001px;">Additionally, it was found that long-tail effects&nbsp;</span></span><span style="line-height: 17.0001px;">severely</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;distorted fitting the shape of the distribution in the&nbsp;"body" for several of the models used. To examine this effect, we also examine models fit against a filtered "no tail" dataset which excludes items over 500k.&nbsp;</span></span><br /><span style="font-family: inherit; line-height: 17.0001px;"><br /></span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">A detailed&nbsp;</span></span><span style="line-height: 17.0001px;">walk-through</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;of the process used to obtain each model is provided in the source Mathematica notebook.</span></span><br /><h4><span style="font-family: inherit; line-height: 17.0001px;"><b>Results</b></span></h4><span style="font-family: inherit; line-height: 17.0001px;">To summarize the results, I have grouped the models by the number of parameters used in the model.</span><br /><span style="font-family: inherit;"><span style="line-height: 17.0001px;"><br /></span><span style="line-height: 17.0001px;"></span></span><br /><div><div class="separator" style="clear: both; text-align: center;"><span style="font-family: inherit; line-height: 17.0001px;"><b>1 Parameter Models</b></span></div><a href="http://3.bp.blogspot.com/-Uf6ghL45FSA/Vi1hlDeQXDI/AAAAAAAAAKc/jmguvqjbBzU/s1600/network%2Blatency%2Bmodeling_96.gif" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><span style="font-family: inherit;"></span></a><span style="font-family: inherit; line-height: 17.0001px;"></span><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-wvG2E1_BJqA/Vi1_yc_camI/AAAAAAAAALI/deBBMwyRlw8/s1600/network%2Blatency%2Bmodeling_41.gif" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-wvG2E1_BJqA/Vi1_yc_camI/AAAAAAAAALI/deBBMwyRlw8/s1600/network%2Blatency%2Bmodeling_41.gif" /></a></div><span style="font-family: inherit; line-height: 17.0001px;"><span style="line-height: 17.0001px;"><br /></span></span><span style="font-family: inherit; line-height: 17.0001px;">For 1-parameter models, I tested selected k values for the Erlang distribution. Shown are curves fit against the full dataset and curves fit on a truncated (non-tail) dataset.</span><br /><span style="font-family: inherit; line-height: 17.0001px;"><br /></span></div><div><div class="separator" style="clear: both; text-align: center;"><span style="font-family: inherit; line-height: 17.0001px;"><b>2 Parameter Models</b></span></div><a href="http://1.bp.blogspot.com/-tDuiVx7mnyE/Vi1h0xoh4PI/AAAAAAAAAKk/RzcvQhKKsLE/s1600/network%2Blatency%2Bmodeling_109.gif" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><span style="font-family: inherit;"><img border="0" src="http://1.bp.blogspot.com/-tDuiVx7mnyE/Vi1h0xoh4PI/AAAAAAAAAKk/RzcvQhKKsLE/s1600/network%2Blatency%2Bmodeling_109.gif" /></span></a><br /><span style="line-height: 17.0001px;"><span style="font-family: inherit;">I tested six variants of 2-parameter models: Erlang (2-component mixture model), Gamma, Log-Normal, and Pareto (<a href="https://en.wikipedia.org/wiki/Pareto_distribution#Pareto_types_I.E2.80.93IV">type II</a>). Both the Gamma and Log-Normal distributions can fit the body shape but are distorted severely by tail effects, very similar to the single-variable Erlang curves.</span></span><br /><span style="line-height: 17.0001px;"><span style="font-family: inherit;"><br /></span></span></div><div><div class="separator" style="clear: both; text-align: center;"><b style="line-height: 17.0001px;"><span style="font-family: inherit;">4 Parameter Models</span></b></div><a href="http://1.bp.blogspot.com/-G-QSu5yDyUY/Vi1iA6vm-UI/AAAAAAAAAKs/blR2D23trac/s1600/network%2Blatency%2Bmodeling_124.gif" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><span style="font-family: inherit;"><img border="0" src="http://1.bp.blogspot.com/-G-QSu5yDyUY/Vi1iA6vm-UI/AAAAAAAAAKs/blR2D23trac/s1600/network%2Blatency%2Bmodeling_124.gif" /></span></a><br /><span style="font-family: inherit;"><span style="line-height: 17.0001px;">I tested three models with four parameters. Notably, the Pareto (type IV) model fits both the body and the tail quite well. I was also surprised that&nbsp;</span></span><span style="line-height: 17.0001px;">neither</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;the hypoexponential nor Erlang mixture models&nbsp;converged on the body shape.</span></span><br /><span style="font-family: inherit; line-height: 17.0001px;"><br /></span></div><div><div><div class="separator" style="clear: both; text-align: center;"><span style="font-family: inherit; line-height: 17.0001px;"><b>5+ Parameter Models</b></span></div><a href="http://3.bp.blogspot.com/-gsmOmK4BgRw/Vi1iZdU7vWI/AAAAAAAAAK0/Z027Av_VOrU/s1600/network%2Blatency%2Bmodeling_133.gif" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><span style="font-family: inherit;"><img border="0" src="http://3.bp.blogspot.com/-gsmOmK4BgRw/Vi1iZdU7vWI/AAAAAAAAAK0/Z027Av_VOrU/s1600/network%2Blatency%2Bmodeling_133.gif" /></span></a></div><span style="font-family: inherit; line-height: 17.0001px;"><br /></span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">I also tested a variety of models that had 5 to 8 parameters. For details on the construction of these models, please refer to the source notebook. Different models fit different parts of the curve quite closely, and they seem to have similar performance determined mainly by the number of variables. This may not be entirely&nbsp;</span></span><span style="line-height: 17.0001px;">surprising</span><span style="font-family: inherit;"><span style="line-height: 17.0001px;">&nbsp;if you consider they are all based on exponential distributions, but it is a notable result - the choice of distribution may matter less than how many variables you choose to allow in your model. All of these models were fit against the entire dataset, unfiltered and unbiased.</span></span></div><div class="separator" style="clear: both; text-align: center;"><a href="https://www.blogger.com/" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"></a><a href="https://www.blogger.com/" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"></a></div><div><h4>Conclusion</h4><span style="font-family: inherit;">So what model wins? If I had to choose one, I'd say Pareto, but it depends on things like what you are using the model for and how you need to estimate it. If using a simple model such as Erlang, keep tail effects in mind. Another consideration is how to fit these models; moments, entropy, expectation-maximization, stochastic gradient descent... but that's a topic for another day.</span><br /><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;">For details on these models, I've posted the <a href="https://drive.google.com/open?id=0B5Y-Tw6GZ3GlZkp4VkFIM0pCVkU">Mathematica notebook</a> in CDF format. There is a <a href="https://www.wolfram.com/cdf-player/">free reader</a> available. </span></div>
